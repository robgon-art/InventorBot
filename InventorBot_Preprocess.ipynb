{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InventorBot Preprocess",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robgon-art/InventorBot/blob/main/InventorBot_Preprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iT4onlRbYu4"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbtJZlUFr7km"
      },
      "source": [
        "!pip install keybert\r\n",
        "from keybert import KeyBERT\r\n",
        "model = KeyBERT('distilbert-base-nli-mean-tokens')\r\n",
        "doc = \"Method and apparatus for parking lot metering using activation codes\"\r\n",
        "keywords = model.extract_keywords(doc, keyphrase_ngram_range=(1, 3), stop_words='english', top_n=1)\r\n",
        "print(keywords[0])\r\n",
        "import nltk.data\r\n",
        "nltk.download('punkt')\r\n",
        "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o_48rqPUNh2"
      },
      "source": [
        "from datetime import date, timedelta\r\n",
        "import requests\r\n",
        "\r\n",
        "num_years = 45\r\n",
        "the_start = 1976\r\n",
        "\r\n",
        "for start_year in range(the_start, the_start + num_years):\r\n",
        "  for month in range(1, 13):\r\n",
        "    print(\"get patents\", start_year, month)\r\n",
        "    start_date = date(start_year, month, 1)\r\n",
        "    if month < 12:\r\n",
        "      end_date = date(start_year, month+1, 1)\r\n",
        "    else:\r\n",
        "      end_date = date(start_year+1, 1, 1)    \r\n",
        "    start = start_date\r\n",
        "    end = start + timedelta(weeks=1)\r\n",
        "    f = open(\"/content/drive/MyDrive/patents2/patents_\" + start.strftime('%Y-%m-%d') + \".txt\", \"w\")\r\n",
        "    while start < end_date:\r\n",
        "      if end > end_date:\r\n",
        "        end = end_date\r\n",
        "      print(\"Getting patents for\", start.strftime('%Y-%m-%d'), \"to\", end.strftime('%Y-%m-%d'))\r\n",
        "\r\n",
        "      resp = requests.get('https://api.patentsview.org/patents/query?' + \r\n",
        "                          'q={\"_and\":[{\"_gte\":{\"patent_date\":\"' + start.strftime('%Y-%m-%d') + '\"}},' +\r\n",
        "                          '{\"_lt\":{\"patent_date\":\"' +  end.strftime('%Y-%m-%d') + '\"}}]}' +\r\n",
        "                          '&f=[\"patent_title\",\"patent_abstract\"]&o={\"page\":1,\"per_page\":10000}')\r\n",
        "      \r\n",
        "      if resp.json()[\"patents\"] is None:\r\n",
        "        break\r\n",
        "\r\n",
        "      for patent in resp.json()[\"patents\"]:\r\n",
        "        if patent[\"patent_abstract\"] is not None:\r\n",
        "          title = patent[\"patent_title\"]\r\n",
        "          keywords = model.extract_keywords(title, keyphrase_ngram_range=(1, 3), stop_words='english', top_n=1)\r\n",
        "          if (len(keywords) == 0):\r\n",
        "            keywords = title.lower()\r\n",
        "          f.write(\"KEYWORDS: \" + keywords[0] + \"\\n\")\r\n",
        "          f.write(\"TITLE: \" + title + \"\\n\")\r\n",
        "          abstract = patent[\"patent_abstract\"]\r\n",
        "          sentences = tokenizer.tokenize(abstract)\r\n",
        "          short_abstract = \" \".join(sentences[0:2])\r\n",
        "          f.write(\"ABSTRACT: \" + short_abstract + \"\\n\")\r\n",
        "          f.write(\"***\\n\")\r\n",
        "          count += 1\r\n",
        "      print(end.strftime('%Y-%m-%d'), resp.json()[\"total_patent_count\"], \"total patents:\", f'{count:>10}')\r\n",
        "      start += timedelta(weeks=1)\r\n",
        "      end += timedelta(weeks=1)\r\n",
        "  f.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}